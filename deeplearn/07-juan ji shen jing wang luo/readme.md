# 卷积神经网络（Convolutional Neural Network，CNN）

CNN 被用于图像识别、语音识别等各种场合
在图像识别的比赛中，基于 深度学习的方法几乎都以 CNN 为基础。

CNN 中新出现了卷积层（Convolution 层）和池化层（Pooling 层）。

* 相邻层的所有神经元之间都有连接，这称为全连接（fully-connected）


CNN 的 层的连接顺序是“Convolution - ReLU -（Pooling） ”（ Pooling 层有时会被省 略）。
这可以理解为之前的“Affine - ReLU”连接被替换成了“Convolution ReLU -（Pooling）”连接。

# 1.卷积层

## 1.1 为什么卷积层，而不是全连层
全连接层缺点：数据的形状被“忽视”了。如1x28x28被排成1列，784个数据形式输入到最开始的Affine层。

卷积层可以保持形状不变。当输入数据是图像时，卷积层会以 3 维 数据的形式接收输入数据，
并同样以 3 维数据的形式输出至下一层。

CNN 中，有时将卷积层的输入输出数据称为特征图（feature map）。

* 卷积层的输入数据称为输入特征图（input feature map）
* 输 出 数据称为输出特征图（output feature map）

## 1.2 卷积运算
卷积运算相当于图形滤波器(`滤波器`，也叫做`核`)

卷积运算的**偏置**：向应用了滤波器的元素加上某个固定值（`偏置`）

在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据（比 如 0 等），这称为**填充**（padding）
应用滤波器的位置间隔称为**步幅**（stride）

通道方向上有多个特征图时，会按通道 进行输入数据和滤波器的卷积运算，并将结果相加，从而得到输出。


- 输入数据(C,H,W),对一个滤波器(C,FH,FW)，输出数据(1,OH,OW). 如果FN个滤波器(FN, C, FH, FW)，输出数据(FN,OH,OW)特征图。
将得到数据方块传递给下一层，这是CNN的`处理流`。

## 1.3 批处理

mini-batch, (batch_num, channel, height, width)

输入数据(N, C, H, W) -> 滤波器(FN, C, FH, FW) -> 输出数据(N, FN, OH, OW) + 偏置(FN, 1, 1, 1) -> 输出数据(N, FN, OH, OW)

# 2.池化层

池化是缩小高、长方向上的空间的运算。Max 池化的处理顺序

除了`Max 池化`之外，还有 `Average池化`等。相对于 Max 池化是从 目标区域中取出最大值，Average 池化则是计算目标区域的平均值。 
在图像识别领域，主要使用 Max 池化。因此，本书中说到“池化层” 时，指的是 Max 池化。

池化层特征：
* 没有要学习的参数：池化只是从目标区域中取最大值（或者平均值）
* 通道数不发生变化：经过池化运算，输入数据和输出数据的通道数不会发生变化。
* 对微小的位置变化具有鲁棒性（健壮）：输入数据发生微小偏差时，池化仍会返回相同的结果。


在卷积层的实现中，都使用了im2col, image to column