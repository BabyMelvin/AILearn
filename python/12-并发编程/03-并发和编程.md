## 12.4 给关键部分加锁

对多线程程序中临界区加锁避免竞争条件。使用threading库中的Lock对象，就像下边例子：

```python
import threading 
class SharedCouter:
	'''
	a counter object that can be shared by multiple threads
	'''
	def __init__(self,inital_value=0):
		self._value=inital_value
		self._value_lock=threading.Lock()

	def incr(self,delta=1):
		'''		
		increment the counter with locking
		'''
		with self._value_lock:
			self._value+=delta
	def decr(self,delta=1):
		'''
		decrement the counter with locking
		'''
		with self._value_lock:
			self._value-=delta
```
Lock对象和with语句块一起使用可以保证互斥执行，执行结束自动释放。

为了避免竞争条件，最好在临界区使用锁。

```python
import threading
class SharedCounter:
	'''
	a counter object that can be shared by multiple threads
	'''
	def __init__(self,initial_value=0):
		self._value=initial_value
		self._value_lock=threading.Lock()

	def incr(self,delta=1):
		'''
		increment the counter with locking
		'''
		self._value_lock.acqurie()
		self._value+=delta
		self._value_lock.realese()

	def decr(self.delta=1):
		'''
		decrement the counter with locking
		'''
		self._value_lock.acquire()
		self._value-=delta
		self._value_lock.release()
```

threading 还提供其他同步原语。RLock和Semaphore对象，如果只是简单的对象进行锁定，不应该使用它们。

一个RLock(可重入锁)可以被同一个线程多次获取，主要用来实现基于监测对象模式的锁定和同步。在使用这种锁情况下，当锁被持有时，只有一个线程可以完整函数或类中方法。

```python
import threading
class SharedCounter:
	'''
	A counter object that can be shared by multiple threads
	'''
	_lock=threading.RLock()
	def __init__(self,initial_value=0):
		self._value=initial_value
	def incr(self,delta=1):
		'''
		increment the counter with locking
		'''
		with SharedCounter._lock:
			self._value+=delta

	def decr(self,delta=1):
		'''
		decrement the counter with locking
		'''
		with SharedCounter._lock:
			self.incr(-delta)
		
```
上边没有对每个实例中的可变对象加锁，而是用一个所有实例共享的类级锁。无论多少实例都只有一个锁，大量使用内存效率更高。也有缺点，频繁使用，会出现争用锁的情况。

信号量对象一个建立在共享计数器基础上同步原语。如果计数器不为0，with语句将计数器减1，线程被允许执行。with语句结束，计数器加1.如果计数器为0，线程将被阻塞，直到其他线程将计数器加1.

尽管可以使用信号量为程序增加复杂性会影响程序性能，相对于简单地作为锁使用。信号量更适用于那些需要在线程之间引入信号或者限制程序。比如，需要限制一段代码的并发访问量，可视使用信号量完成：

```python
from threading import Semaphore
import urllib.request

# at most ,five threads allowed to run at once

_fetch_url_sema=Semaphore(5)

def fetch_url(url):
	with _fetch_url_sema:
		return urllib.request.urlopen(url)
```

## 12.5 防止死锁的加锁机制
一个多线程如何避免死锁的情况？解决方法一种方案为程序中每个锁分配一个唯一的id，然后只允许按照升序规则使用多个锁。这个规则使用上下文管理器是非常容易实现的

```python
# 小加入，高的删除
import threading
from contextlib import contextmanager

# thread-local state to store information on locks already acquired
_local=threading.local()

@contextmanager
def acquire(*locks):
	# sort locks by object identifier
	locks=sorted(locks,key=lambda x:id(x))

	# make sure lock order of previously acquired locks is not voilated
	acquired = getattr(_local,'acquired',[])
	
	# acquire all of the locks
	acquired.extend(locks)
	_local.acquired=acquired
	if acquired and max(id(lock) for lock in acquired)>=id(locks[0]):
		raise RuntimeError('lock order violation')

	try:
		for lock in locks:
			lock.acquire()
		yield
	finally:
		# release lock in reverse order of acquisition
		for lock in reversed(locks):
			lock.release()
		del acquired[-len(lock):]
```
使用上下文管理器，按照正常途径创建一个对象，不论是单个锁还是多个锁都使用`acquire()`函数来申请锁：

```python
import threading 
x_lock=threading.Lock()
y_lock=threading.Lock()

def thread_1():
	while True():
		with acquire(x_lock,y_lock):
			print('Thread-1')

def thread_2():
	while True:
		with acquire(y_lock,x_lock):
			print('Thread-2')
			
t1=threading.Thread(target=thread_1)
t1.daemon=True
t1.start()

t2=threading.Thread(target=thread_2)
t2.daemon=True
t2.start()
```
即使不同的顺序获取锁也没有发生死锁，关键在于，这段代码，对这些锁进行了排序。通过排序，不管用户使用什么顺序请求，这些锁都会按照固定的顺序来被获取.

如果多个acquire()操作被嵌套调用，可以使用线程本地存储(TLS)来检测潜在死锁问题。

```python
import threading
x_lock=threading.Lock()
y_lock=threading.Lock()

def thread_1():
	while True:
		with acquire(x_lock):
			with acquire(y_lock):
				print('Thread-1')

def thread_2():
	while True:
		with acquire(y_lock):
			with acquire(x_lock):
				print('Thread-2')
t1=threading.Thread(target=thread_1)
t1.daemon=True
t1.start()

t2=threading.Thread(target=thread_2)
t2.daemon=True
t2.start()
```
如果运行，**必定一个线程发生崩溃**：发生崩溃原因在于，每个线程记录着自己已获取到的锁。acquire()函数会检查之前已经获取的锁列表，锁按照升序排序获取的，函数会认为之前已获取的锁id必定小于新申请到的锁，这是会出发异常。
```python
RuntimeError:Lock Order Violation
```

近可能保证每一个线程只能保持一个锁，这样就不会被死锁问题困扰。一旦有线程同时申请多个锁，一切就不可预料了。

**看门狗计数器**比较常用的死锁检测与恢复的方案。当线程正常运行的时候会每隔一段时间重置计数器，没有发生死锁一切运行正常，一旦死锁，无法重置计数器导致定时器超时，这程序会通过重置自身恢复到正常状态。

**另一种解决死锁问题方案**，在进程获取锁的时候会严格按照对象id升序排列获取。主要思想是单纯滴按照对象id递增顺序加锁不会产生循环依赖，而循环依赖是死锁一个必要条件，从而避免程序进入死锁状态。

## 12.6 保存线程的状态信息

需要保存正在运行线程的状态，这个状态对于其他线程是不可见的。多线程编程中，只需要当前运行线程的状态。可以使用`thread.local()`创建一个本地线程存储对象。这个对象的属性的保存和读取操作都只会对执行线程可见，而其他线程并不可见。

```python
from socket import socket,AF_INET,SOCK_STREAM
import threading
class LazyConnection:
	def __init__(self,address,famlily=AF_INET,type=SOCK_STREAM):
		self.address=address
		self.family=AF_INET
		self.type=SOCK_STREAM
		self.local=threading.local()

	def __enter__(self):
		if hasattr(self.local,'sock'):
			raise RuntimeError('already connected')

		self.local.sock=socket(self.family,self.type)
		self.local.sock.connect(self.address)
		return self.local.sock

	def __exit__(self,exc_ty,exc_val,tb):
		self.local.sock_close()
		def self.local.sock
```

对于`self.local`属性使用，被初始化为一个`threading.local()`实例。其他方法被操作存储为`self.local.sock`的套接字对象.有了这些多线程中安全的使用`LazyConnection`实例:

```python
from functools import partial
def test(conn):
	with conn as s:
		s.send(b`GET /index.html HTTP/1.0\r\n`)
		s.send(b'Host: www.python.org\r\b')
		s.send(b'\r\n')
		resp=b''.join(iter(partial(s.recv,8192),b''))
	print('got {} bytes'.format(len(resp)))

if __name__=='__main__':
	conn=LazyConnetion(('www.python.org',80))
	t1=threading.Thread(target=test,args=(conn,))
	t2=threading.Thread(target=test,args=(conn,))
	t1.start()
	t2.start()
	t1.join()
	t2.join()
```
之所以行得通原因是每个线程会创建一个自己专属的套接字连接，它们不会相互影响。

当某个对象呗多个对象线程使用，一些专用系统资源，比如套接字或文件。不能所有资源共用一个对象，对产生混乱。本地线程存储通过让这些资源只能在使用的线程中可见 来解决这个问题。

例子中使用thread.local()可以让LazyConnetion类支持一个线程一个连接，而不是对于所有进程都只有一个连接。原理是每个`threading.local()`实例为每个线程维护这一个单独的实例字典，所有普通实例操作比如获取、修改和删除值仅仅操作这个字典。每个线程使用一个独立的字典就可以保证数据的隔离。

## 12.7 创建一个线程池

创建一个工作这线程池，用来响应客户端请求或执行其他的工作。`concurrent.features`函数有一个`ThreadPoolExecutor`类可以被用来完成这个任务。下面是一个简单TCP服务器，使用了一个线程池来响应客服端：

```python
from socket import AF_INET,SOCK_STREAM,socket
from concurrent.futures import ThreadPoolExecutor

def echo_client(sock,client_addr):
	'''
	handle a client connection
	'''
	print('got a connetion from',client_addr)
	while True:
		msg=scok.recv(65536)
		if not msg:
			break;
		sock.sendall(msg)
	print('client closed connection')
	sock.close()

def echo_server(addr):
	pool=ThreadPoolExecutor(128):
	sock=socket(AF_INET,SOCK_STREAM)
	sock.bind(addr)
	sock.listen(5)
	while True:
		client_sock,client_addr=sock.accept()
	pool.submit(echo_client,client_sock,client_addr)

echo_server(('',15000))
```

手动创建一个线程池，通过Queue来轻松实现。

```python
from socket import socket,AF_INET,SOCK_STREAM
from threading import Thread
from queue import Queue

def echo_clieng(q):
	'''
	handle a client connection
	'''
	sock,client_addr=q.get()
	print('got connetion from',client_addr)
	while True:
		msg=sock.recv(65536)
		if not msg:
			break
		sock.sendall(msg)

	print('client closed connetion')
	sock.close()

def echo_server(addr,nworkers):
	# launcher the client workers
	q=Queue()
	for n in range(nworkers):
		t = Thread(target=echo_client,args=(q,))
		t.daemon=True
		t.start()
	# run the server
	sock=socket(AF_INET,SOCK_STREAM)
	sock.bind(addr)
	sock.listen(5)
	while True:
		client_sock,client_addr=sock.accept()
		q.put((client_sock,client_addr))
echo_server(('',15000),128)
```
ThreadPoolExecutor相对于手动实现一个处于使得任务提交者更方便从调用函数中获取返回值：

```python
from concurrent.future import ThreadPoolExecutor
import urllib.request

def fetch_url(url):
	u=urllib.request.urlopen(url)
	data=u.read()
	return data

pool=ThreadPoolExecutor(10)

# submit work to the pool
a=pool.submit(fetch_url,'http://www.python.org')
b=pool.submit(fetch_url,'http://www.pypy.org')

# get the results back
X=a.result()
Y=b.result()
```

应该避免编写线程数量可以无限制的增长的程序。
```python
from threading imoort Thread
from socket import socket,AF_INET,SOCK_STREAM

def echo_client():
	'''
	handle a client connection
	'''
	print('got connection from',client_addr)
	while True:
		msg=sock.recv(653336)
		if not msg:
			break
		sock.sendall(msg)
	print('clinet closed connection')
	sock.close()

def echo_server(addr,nworkers):
	# run the server
	sock=socket(AF_INET,SOCK_STREAM)
	sock.bind(addr)
	sock.listen(5)
	while True:
		client_sock,client_addr=sock.accept()
	t=Thread(target=echo_client,args=(client_sock,client_addr))
	t.daemon=True
	t.start()

echo_server(('',15000))
```
尽管这也可以工作，但是不能抵御有人试图穿建大量服务器资源枯竭而崩溃的攻击行为。使用预先初始化的线程池，可以设置同时运行线程的上限数量。可以使用虚拟内存大小，使用`threading.stack_size()`函数来降低它

```python
import threading
threading.stack_size(65536)
```

